---
type: page
title: The Big O Notation
tag: Algorithms
author: Namish
---

## Time and Space Complexity

![big-0](/bigo/big-o.png)

### Need For Big O and Time Complexity

Suppose these two codes written in python. Their task is to find the letter **i** in the word inputted by the user.

```py
word = input()
if i in word:
    print("Found i")
```

The second code

```py
word = input()
for letter in word:
    if letter == 'i':
        print("Found i")
```

Now if we were to run the first code on a piece of junk, and second one on a supercomputer, the supercomputer might execute it faster, but in the terms of Big O, the first code is faster. This is because the first code has a time complexity of **O(1)** and the second code has a time complexity of **O(n)**.

<br/>
So, Time Complexity is a way to represent how much time an algorithm takes to run, in terms of the input size. How do we see it mathematically? Well we can plot a graph of the time taken by the algorithm to run, against the input size. This graph is called the Time Complexity Graph. So let us take some example code.

```c
int main() {
    for (int i = 0; i < n; i++) {
        printf("Hello, World!");
    }
}
```

Here we can see that **n** and time are directly proportional. Therefore the graph would look something like this. Theta in the graph is called the rate of increase of time taken by the algorithm. And this rate is referred to as the Time Complexity of the algorithm.

![graph](/bigo/simple-graph.png)

Similarly space complexity is a way to represent how much space an algorithm takes to run, in terms of the input size. It is also represented in terms of the input size.

### Big O Notation

Big O Notation is a way to represent the time complexity of an algorithm. It is a mathematical notation that describes the limiting behavior of a function when the argument tends **towards a particular value** or **infinity**. It is used to **describe the upper bound** of the time complexity of an algorithm. It's like saying, "The time complexity of this algorithm **will never be more than this.**" We write as O(x), where x is the term of time complexity with the highest degree (without the coeffecient) of the algorithm. You just need to remember 3 rules while calculating the Big O of an algorithm.

1. Always consider the worst case scenario.
2. Ignore the constants.
3. Ignore the lower terms.

### Analyzing Algorithms

Let's take an example of a simple algorithm to swap two variables.

```c
void swap(int a, int b) {
    int temp = a;
    a = b;
    b = temp;
}
```

We will assume that each statement in the code takes 1 unit of time to execute. So the time function would be **T(n) = 1 + 1 + 1 = 3**. For the space complexity, we have **a**, **b**, and the **temp** variable, therefore the space function would be **S(n) = 1 + 1 + 1 = 3**. In terms of Big O, the time complexity would be **O(1)** and the space complexity would also be **O(1)**.

### Frequncy Count Method

This method is used to calculate the time complexity of an algorithm. It is done by counting the number of times a statement is executed. Let's take an example of a simple algorithm to find the sum of the first **n** natural numbers.

```c
int main() {
  sum = 0;
  n = 10;
  for (int i = 1; i <= n; i++) {
    sum += i;
  }
}
```

Here the for loop is actually made of three smaller statements. The initialization of **i**, the condition, and then finally, the increment. The initialization would only be executed once. The condition **i \<= n** would be checked for a **n+1** times (because it is \<=) and then finally the increment will happen **n** times.

Therefore, the time complexity of this algorithm would be **T(n) = 1 + 1 + 1 + n + n = 2n + 3** (the beginning 2 ones are for initializing sum and n).
In terms of Big O, the time complexity would be **O(n)**.

For the space complexity, we have **sum**, **n**, and **i**, therefore the space function would be **S(n) = 1 + 1 + 1 = 3**.
In terms of Big O, the space complexity would be **O(1)**.

<br/>
Let us take another example of adding two matrices, where the size is given as **n x n**.

```c
void add(int *A, int *B, int *C, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            C[i * n + j] = A[i * n + j] + B[i * n + j];
        }
    }
}
```

Now we know that the first for loop would run for **n** times, the second nested for loop would run for **n * (n + 1)** times and each line in the second nested loop would run for **n * n** times. Therefore the time complexity turns out to  be **T(n) = n^2 + n + n^2 = 2n^2 + n**

For the space complexity, we have A, B, C and i,j,n.

A, B and C are 2 dimensional arrays, therefore they would take **n * n** space. And i, j, n would take **1** space. Therefore the space complexity would be **S(n) = 3n^2 + 3**.
In terms of Big O, the time complexity would be **O(n^2)** and the space complexity would also be **O(n^2)**.
